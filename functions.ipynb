{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def stdout_redirected(new_stdout):\n",
    "    save_stdout = sys.stdout\n",
    "    sys.stdout = new_stdout\n",
    "    try:\n",
    "        yield None\n",
    "    finally:\n",
    "        sys.stdout = save_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_eta_lines(run_number):\n",
    "    input_file_path = f'.\\\\model_runs\\\\{run_number}\\\\log.txt'\n",
    "    \n",
    "    with open(input_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Filter out lines containing \"- ETA: \"\n",
    "    lines = [line for line in lines if \"- ETA: \" not in line]\n",
    "\n",
    "    # Save the modified content back to the same file\n",
    "    with open(input_file_path, 'w') as f:\n",
    "        f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_range(a, b, x):\n",
    "    x = x+1\n",
    "    a = a -0.01\n",
    "    b = b + 0.01\n",
    "\n",
    "    if round(a,0) == 46:\n",
    "        if x > 11:\n",
    "            x = 11\n",
    "            print(\"Warning: 10 is the highest number of divisions possible for latitudes. So the number of divsions is set to maximum that is 10.\")\n",
    "    \n",
    "    if round(a,0)==10:\n",
    "        if x > 15:\n",
    "            x = 15\n",
    "            print(\"Warning: 14 is the highest number of divisions possible for longitudes. So the number of divsions is set to maximum that is 14.\")\n",
    "\n",
    "    if x < 2:\n",
    "        raise ValueError(\"Number of divisions must be at least 2\")\n",
    "\n",
    "    step = (b - a) / (x - 1)  # Calculate the step size for equal divisions\n",
    "    result = [round(a + i * step, 2) for i in range(x)]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1]\n"
     ]
    }
   ],
   "source": [
    "def generate_array(b):\n",
    "    array = [b] * 12\n",
    "    array[0] = array[1] = array[2] = array[11] = 1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_month_fraction_array(month_fraction_array):\n",
    "    # Define the indices where 1 should be added\n",
    "    indices_to_pad = [0, 1, 2, 11]\n",
    "    \n",
    "    # Create the padded array by inserting 1 at specified indices\n",
    "    month_fraction_array_padded = month_fraction_array.copy()\n",
    "    for idx in indices_to_pad:\n",
    "        month_fraction_array_padded.insert(idx, 1)\n",
    "    \n",
    "    return month_fraction_array_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(ndsi_ds):\n",
    "    time_ndsi = ndsi_ds[\"time\"].values\n",
    "    df_time = pd.DataFrame({\"date\": time_ndsi})\n",
    "    df_time[[\"date\"]]= df_time[['date']].astype(str)\n",
    "    df_time['date'] = pd.to_datetime(df_time['date'])\n",
    "    df_time['date'] = df_time['date'] + pd.Timedelta(hours=12)\n",
    "    selected_dates = df_time['date'].values\n",
    "    return selected_dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info_about_latitude_longitude_groups(temp):\n",
    "    temp = temp[temp[\"Date\"] == temp.Date[1]]\n",
    "    grouped_latitudes = temp.groupby('Latitude_Group')['Latitude'].unique().to_dict()\n",
    "    logger.info(\"Latitude Group\")\n",
    "    logger.info(\"{\\n\" + \",\\n\".join(f\" {key}: {value}\" for key, value in grouped_latitudes.items()) + \"\\n}\")\n",
    "\n",
    "    grouped_longitudes = temp.groupby('Longitude_Group')['Longitude'].unique().to_dict()\n",
    "    logger.info(\"Longitude Group\")\n",
    "    logger.info(\"{\\n\" + \",\\n\".join(f\" {key}: {value}\" for key, value in grouped_longitudes.items()) + \"\\n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram for df\n",
    "def plot_before_and_after_month_sampling(df, df_to_delete):\n",
    "    fig1 = px.histogram(df, x='ndsi', nbins=100)\n",
    "    fig1.update_layout(\n",
    "        xaxis_title='Value',\n",
    "        yaxis_title='Frequency',\n",
    "    )\n",
    "\n",
    "    # Plot histogram for df_to_delete\n",
    "    fig2 = px.histogram(df_to_delete, x='ndsi', nbins=100)\n",
    "    fig2.update_layout(\n",
    "        xaxis_title='Value',\n",
    "        yaxis_title='Frequency',\n",
    "    )\n",
    "\n",
    "    # Create subplots with two columns\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=('Before', 'After'))\n",
    "    fig.add_trace(fig1.data[0], row=1, col=2)\n",
    "    fig.add_trace(fig2.data[0], row=1, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Before and after zero sampling in mid-year months',\n",
    "        width=1000,  # Total width of the combined plots\n",
    "        height=400,  # Height of the combined plots\n",
    "    )\n",
    "\n",
    "    # Define the DPI and calculate the scale factor\n",
    "    dpi = 600\n",
    "    default_dpi = 72\n",
    "    scale = dpi / default_dpi\n",
    "\n",
    "    # Export the figure at 300 DPI\n",
    "    plotly_image_path = os.path.join(folder_name, 'before_after_zero_sampling.png')\n",
    "    fig.write_image(plotly_image_path, width=1000, height=400, scale=scale)\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataFrame(df, scenario_array, prediction_array):\n",
    "    df = pd.DataFrame({\n",
    "    \"Date\" : df[\"Date\"].values,\n",
    "    \"Latitude\" : df[\"Latitude\"].values,\n",
    "    \"Longitude\" : df[\"Longitude\"].values,\n",
    "    f\"{scenario_array[0]}\": prediction_array[0].flatten(),\n",
    "    f\"{scenario_array[1]}\": prediction_array[1].flatten(),\n",
    "    f\"{scenario_array[2]}\": prediction_array[2].flatten()\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_show_month_wise_distribution(df_to_delete, df, month_fraction_array_padded, save):\n",
    "    df_to_delete['Date'] = pd.to_datetime(df_to_delete['Date'])\n",
    "\n",
    "    # Extract month from the 'Date' column\n",
    "    df_to_delete['Month'] = df_to_delete['Date'].dt.month\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "\n",
    "    # Create a new figure and subplots\n",
    "    fig, axs = plt.subplots(4, 6, figsize=(20, 10))  # 4 rows, 8 columns for 12 months for both DataFrames\n",
    "\n",
    "\n",
    "    # Plot histograms for each month in df\n",
    "    for month in range(1, 13):\n",
    "        row = (month - 1) // 3  # Calculate the row index for the subplot\n",
    "        col = (month - 1) % 3   # Calculate the column index for the subplot\n",
    "        \n",
    "        # Filter data for the current month in df_to_delete\n",
    "        month_data_df_to_delete = df_to_delete[df_to_delete['Month'] == month]['ndsi']\n",
    "        \n",
    "        # Plot histogram in the corresponding subplot for df_to_delete\n",
    "        axs[row, col].hist(month_data_df_to_delete, bins=20, color='salmon', alpha=0.7)\n",
    "        axs[row, col].set_title(f'Month {month} (before)')\n",
    "        axs[row, col].set_xlabel('NDSI')\n",
    "        axs[row, col].set_ylabel('Frequency')\n",
    "\n",
    "\n",
    "    # Plot histograms for each month in df_to_delete on the right\n",
    "    for month in range(1, 13):\n",
    "        row = (month - 1) // 3  # Calculate the row index for the subplot\n",
    "        col = (month - 1) % 3 + 3  # Shift to the right by 4 columns\n",
    "        \n",
    "        # Filter data for the current month in df\n",
    "        month_data_df = df[df['Month'] == month]['ndsi']\n",
    "        \n",
    "        # Plot histogram in the corresponding subplot for df\n",
    "        axs[row, col].hist(month_data_df, bins=20, color='skyblue', alpha=0.7)\n",
    "        axs[row, col].set_title(f'Month {month} (after) | Fraction = {month_fraction_array_padded[month-1]}')\n",
    "        axs[row, col].set_xlabel('NDSI')\n",
    "        axs[row, col].set_ylabel('Frequency')\n",
    "        \n",
    "        \n",
    "    df = df.drop([\"Month\"], axis=1)\n",
    "    # Adjust layout and display the subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save ==1:\n",
    "        matplotlib_image_path = os.path.join(folder_name, 'each_month_zero_cleaning.png')\n",
    "        plt.savefig(matplotlib_image_path)\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_dates_for_ndsi(limit_of_nans_in_a_timestep = 120):\n",
    "    daily_nan_df = pd.read_csv(r\".\\number_of_nans_for_each_date.csv\")\n",
    "    daily_nan_df['check'] = np.where((daily_nan_df['Number of NaNs'] >= limit_of_nans_in_a_timestep), 1, 0)\n",
    "    date_selection_df = daily_nan_df[daily_nan_df['check'] == 0]\n",
    "    date_selection_df['Date'] = pd.to_datetime(date_selection_df['Date'])\n",
    "    return date_selection_df['Date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def to_array(data, index_climate_parameter):\n",
    "    array = []\n",
    "    n_time_steps = data[0].shape[0]\n",
    "    n_lat, n_lon = data[0].shape[1], data[0].shape[2]\n",
    "    data1 = data[index_climate_parameter]\n",
    "    for b in range(n_time_steps):\n",
    "        data2=data1[b]\n",
    "        for c in range(n_lat):\n",
    "            data3=data2[c]\n",
    "            for d in range(n_lon):\n",
    "                data4=data3[d]\n",
    "                array.append(data4)\n",
    "    array = np.array(array)\n",
    "    return array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_max(df, parameter_name):\n",
    "    param_data = df[df['parameter'] == parameter_name]\n",
    "    if not param_data.empty:\n",
    "        min_val = param_data['min'].values[0]\n",
    "        max_val = param_data['max'].values[0]\n",
    "        return min_val, max_val\n",
    "    else:\n",
    "        return None, None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_array_ndsi(data):\n",
    "    array = []\n",
    "    n_time_steps = data.shape[0]\n",
    "    n_lat, n_lon = data.shape[1], data.shape[2]\n",
    "    data1 = data\n",
    "    for b in range(n_time_steps):\n",
    "        data2=data1[b]\n",
    "        for c in range(n_lat):\n",
    "            data3=data2[c]\n",
    "            for d in range(n_lon):\n",
    "                data4=data3[d]\n",
    "                array.append(data4)\n",
    "    array = np.array(array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def self_defineed_r2(y_test, y_pred):\n",
    "    mean_true = np.mean(y_test)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "    numerator = np.sum((y_test - mean_true)*(y_pred-mean_pred))\n",
    "    denominator1 = math.sqrt(np.sum((y_test - mean_true)**2))\n",
    "    denominator2 = math.sqrt(np.sum((y_pred - mean_pred)**2))\n",
    "\n",
    "    self_defined_r2 =  (numerator/(denominator1*denominator2))**2\n",
    "    return self_defined_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbias(y_test, y_pred):\n",
    "    num = np.sum(y_test - y_pred)\n",
    "    denom = np.sum(y_test)\n",
    "    return num*100/denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nse(y_pred, y_test):\n",
    "    mean_observed = np.mean(y_test)\n",
    "    numerator = np.sum((y_test - y_pred)**2)\n",
    "    denominator = np.sum((y_test - mean_observed)**2)\n",
    "    nse_value = 1 - (numerator / denominator)\n",
    "    return nse_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_n_rmse(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mean_true = np.mean(y_test)\n",
    "    n_rmse = rmse / mean_true\n",
    "    return n_rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xarray-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
